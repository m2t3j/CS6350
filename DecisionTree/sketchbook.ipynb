{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def label_counts(data):\n",
    "   #label_counts = data.iloc[:-1].valuecounts()\n",
    "   label_counts = {}\n",
    "   #look at last column\n",
    "   for i in data.iloc[:, -1]:\n",
    "      if i not in label_counts:\n",
    "         label_counts[i] = 0\n",
    "      label_counts[i] = label_counts[i] + 1\n",
    "   return label_counts\n",
    "\n",
    "### Entropy = - sum(p_i) * log2(p_i)\n",
    "def entropy(data):\n",
    "   label_count = label_counts(data)\n",
    "   total_num_labels = len(data)\n",
    "   entropy = -1*sum((count/total_num_labels)*math.log2((count/total_num_labels)) for count in label_count.values())\n",
    "#    for i in label_counts.values():\n",
    "#       prob = i / total_num_labels\n",
    "#       entropy = -(prob * math.log2(prob))\n",
    "   return entropy\n",
    "\n",
    "### gini index = 1 - sum(p^2)\n",
    "def gini_index(data):\n",
    "   label_count = label_counts(data)\n",
    "   total_num_lables = len(data)\n",
    "   gini = 1 - sum((count / total_num_lables) ** 2 for count in label_count.values())\n",
    "   return gini\n",
    "\n",
    "### me = 1 - (majority class / total num)\n",
    "def majority_error(data):\n",
    "   label_count = label_counts(data)\n",
    "   total_num_labels = len(data)\n",
    "   majority_label = max(label_count.values())\n",
    "   return 1 - (majority_label / total_num_labels)\n",
    "\n",
    "#split the data into subsets where the it has every unique value in each attribute name.\n",
    "def split_data(data, attribute_name):\n",
    "    splits = {}\n",
    "    for _, row in data.iterrows():\n",
    "        value = row[attribute_name]\n",
    "        if value not in splits:\n",
    "            splits[value] = []\n",
    "        splits[value].append(row)\n",
    "    return {key: pd.DataFrame(value) for key, value in splits.items()}\n",
    "\n",
    "# IG = total entropy - attribute weigthed average entropy\n",
    "def information_gain(data, attribute_name, criterion_func):\n",
    "    total_entropy = criterion_func(data)\n",
    "    #split the data based on attribute\n",
    "    splits = split_data(data, attribute_name)\n",
    "    total_size = len(data)\n",
    "    weighted_entropy = 0\n",
    "    for subset_of_data in splits.values():\n",
    "        subset_size = len(subset_of_data)\n",
    "        #calculate the weigthed average of the attribute using its subset size * its entropy\n",
    "        weighted_entropy += (subset_size / total_size) * criterion_func(subset_of_data)\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def choose_best_attribute(data, attributes, criterion_func):\n",
    "    best_gain = -1\n",
    "    best_attr = None\n",
    "    for attr_name in attributes:\n",
    "        # call the information gain function on each attribute. The highest ig is the best attribute to split on.\n",
    "        gain = information_gain(data, attr_name, criterion_func)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attr = attr_name\n",
    "    return best_attr\n",
    "\n",
    "\n",
    "def lets_build_a_tree_baby(data, attributes, criterion_func, depth=0, max_depth=None):\n",
    "    labels = data.iloc[:, -1]\n",
    "    \n",
    "    # Base cases: all labels are the same, or no attributes left, or max depth reached\n",
    "    if len(labels.unique()) == 1:\n",
    "        return labels.iloc[0]\n",
    "    if not attributes or (max_depth is not None and depth == max_depth):\n",
    "        return get_most_common_label(labels)\n",
    "    \n",
    "    # Choose the best attribute to split on\n",
    "    best_attr = choose_best_attribute(data, attributes, criterion_func)\n",
    "    \n",
    "    # Split the dataset on the best attribute\n",
    "    tree = {best_attr: {}}\n",
    "    splits = split_data(data, best_attr)\n",
    "    remaining_attributes = [attr for attr in attributes if attr != best_attr]\n",
    "    \n",
    "    # Recursively build the tree for each split\n",
    "    for attr_value, subset in splits.items():\n",
    "        tree[best_attr][attr_value] = lets_build_a_tree_baby(subset, remaining_attributes, criterion_func, depth + 1, max_depth)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "#broken. please help\n",
    "def get_most_common_label(labels):\n",
    "    labels = label_counts(pd.DataFrame(labels))\n",
    "    return max(labels, key=labels.get)\n",
    "\n",
    "\n",
    "def predict(tree, example):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attr = next(iter(tree))\n",
    "    value = example[attr]\n",
    "    subtree = tree[attr].get(value)\n",
    "    if subtree is None:\n",
    "        return None \n",
    "    return predict(subtree, example)\n",
    "\n",
    "# Function to evaluate the decision tree accuracy\n",
    "def accuracy(tree, data):\n",
    "    correct = 0\n",
    "    #iterrows( ) is a function that goes through every row,\n",
    "    for _, row in data.iterrows():\n",
    "        prediction = predict(tree, row)\n",
    "        # predict the value, if the predicted value is equal to the actual value, then the correct counter goes up one\n",
    "        if prediction == row.iloc[-1]: \n",
    "            correct += 1\n",
    "    return correct / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error(tree, data):\n",
    "    acc = accuracy(tree, data)\n",
    "    return 1 - acc\n",
    "\n",
    "#\n",
    "def run_different_depths(train_data, test_data, attributes, depths):\n",
    "    results = {\n",
    "        'Depth': [],\n",
    "        'Heuristic': [],\n",
    "        'Train Error': [],\n",
    "        'Test Error': []\n",
    "    }\n",
    "    \n",
    "    for depth in depths:\n",
    "        print(f\"\\nMaking Tree with max depth = {depth}\")\n",
    "\n",
    "        tree_info_gain = lets_build_a_tree_baby(train_data, attributes, entropy, max_depth=depth)\n",
    "        train_error_ig = prediction_error(tree_info_gain, train_data)\n",
    "        test_error_ig = prediction_error(tree_info_gain, test_data)\n",
    "\n",
    "        tree_majority_error = lets_build_a_tree_baby(train_data, attributes, majority_error, max_depth=depth)\n",
    "        train_error_me = prediction_error(tree_majority_error, train_data)\n",
    "        test_error_me = prediction_error(tree_majority_error, test_data)\n",
    "\n",
    "        tree_gini_index = lets_build_a_tree_baby(train_data, attributes, gini_index, max_depth=depth)\n",
    "        train_error_gi = prediction_error(tree_gini_index, train_data)\n",
    "        test_error_gi = prediction_error(tree_gini_index, test_data)\n",
    "\n",
    "        # Record results for Information Gain\n",
    "        results['Depth'].append(depth)\n",
    "        results['Heuristic'].append('Information Gain(Entropy)')\n",
    "        results['Train Error'].append(train_error_ig)\n",
    "        results['Test Error'].append(test_error_ig)\n",
    "\n",
    "        # Record results for Majority Error\n",
    "        results['Depth'].append(depth)\n",
    "        results['Heuristic'].append('Majority Error')\n",
    "        results['Train Error'].append(train_error_me)\n",
    "        results['Test Error'].append(test_error_me)\n",
    "\n",
    "        \n",
    "        results['Depth'].append(depth)\n",
    "        results['Heuristic'].append('Gini Index')\n",
    "        results['Train Error'].append(train_error_gi)\n",
    "        results['Test Error'].append(test_error_gi)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: csv files don't have a header\n",
    "train_data = pd.read_csv('car/train.csv', header=None)\n",
    "test_data = pd.read_csv('car/test.csv', header=None)\n",
    "\n",
    "train_data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "test_data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "\n",
    "# for most of the functions to work, they will need the names of the dataset columns, or the attributes\n",
    "attributes = list(train_data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making Tree with max depth = 1\n",
      "\n",
      "Making Tree with max depth = 2\n",
      "\n",
      "Making Tree with max depth = 3\n",
      "\n",
      "Making Tree with max depth = 4\n",
      "\n",
      "Making Tree with max depth = 5\n",
      "\n",
      "Making Tree with max depth = 6\n",
      "\n",
      "Prediction Errors Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Heuristic</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.296703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.296703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.296703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.315934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.262363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.184066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.146978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.243132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.133242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.104396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.179945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.104396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>Information Gain(Entropy)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>Majority Error</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.199176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>Gini Index</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth                  Heuristic  Train Error  Test Error\n",
       "0       1  Information Gain(Entropy)        0.302    0.296703\n",
       "1       1             Majority Error        0.302    0.296703\n",
       "2       1                 Gini Index        0.302    0.296703\n",
       "3       2  Information Gain(Entropy)        0.222    0.222527\n",
       "4       2             Majority Error        0.301    0.315934\n",
       "5       2                 Gini Index        0.222    0.222527\n",
       "6       3  Information Gain(Entropy)        0.181    0.196429\n",
       "7       3             Majority Error        0.242    0.262363\n",
       "8       3                 Gini Index        0.176    0.184066\n",
       "9       4  Information Gain(Entropy)        0.082    0.146978\n",
       "10      4             Majority Error        0.130    0.243132\n",
       "11      4                 Gini Index        0.089    0.133242\n",
       "12      5  Information Gain(Entropy)        0.027    0.104396\n",
       "13      5             Majority Error        0.043    0.179945\n",
       "14      5                 Gini Index        0.027    0.104396\n",
       "15      6  Information Gain(Entropy)        0.000    0.125000\n",
       "16      6             Majority Error        0.000    0.199176\n",
       "17      6                 Gini Index        0.000    0.125000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = range(1, 7)  \n",
    "results_df = run_different_depths(train_data, test_data, attributes, depths)\n",
    "\n",
    "\n",
    "print(\"\\nPrediction Errors Table:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c. As the depth of the tree gets deeper, both the training error and test error decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>312</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>feb</td>\n",
       "      <td>369</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1938</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>aug</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>59</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>10</td>\n",
       "      <td>jul</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2646</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>apr</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0            1        2          3   4     5    6    7         8   9    10  \\\n",
       "0  41     services  married  secondary  no     0  yes   no   unknown   5  may   \n",
       "1  48  blue-collar   single  secondary  no   312  yes  yes  cellular   3  feb   \n",
       "2  55   technician  married  secondary  no  1938   no  yes  cellular  18  aug   \n",
       "3  54       admin.  married   tertiary  no    59  yes   no  cellular  10  jul   \n",
       "4  34   management   single   tertiary  no  2646   no   no  cellular  14  apr   \n",
       "\n",
       "    11  12   13  14       15   16  \n",
       "0  114   2   -1   0  unknown   no  \n",
       "1  369   2   -1   0  unknown   no  \n",
       "2  193   1  386   3  success  yes  \n",
       "3  268   1   -1   0  unknown   no  \n",
       "4  142   1   -1   0  unknown  yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('bank/train.csv', header=None)\n",
    "test_data = pd.read_csv('bank/test.csv', header=None)\n",
    "\n",
    "train_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat486",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
